# 数据分析案例研究2

## 1.案例概述

在第二个案例研究中，我将分析[由环境保护局 (EPA) 提供的燃料经济性数据](https://www.epa.gov/compliance-and-fuel-economy-data/data-cars-used-testing-fuel-economy)。

### 什么是燃料经济性？

摘自维基百科关于*汽车燃料经济性*的[页面](https://en.wikipedia.org/wiki/Fuel_economy_in_automobiles)：

> 汽车的燃料经济性是车辆行驶距离与消耗的燃料量之间的燃料效率关系。消耗量可以用行使一段距离所需的燃料量，或者消耗的每单位燃料所走的距离来表示。

## 2.数据概述

我们将在学习的过程中更详细地了解这些特征。我们需要了解我们使用的数据是什么。

以下是数据的来源页面:

- [EPA 燃料经济性练习](https://www.epa.gov/compliance-and-fuel-economy-data/data-cars-used-testing-fuel-economy).
- [能源部燃料经济数据](http://www.fueleconomy.gov/feg/download.shtml/).

## 3.数据属性

- [README.txt 下载链接](http://www.fueleconomy.gov/feg/epadata/Readme.txt)
- [PDF 链接](http://www.fueleconomy.gov/feg/EPAGreenGuide/GreenVehicleGuideDocumentation.pdf)。

### 习题 

发动机排量的单位是什么？

- [x] 升
- [ ] 立方英寸
- [ ] 立方厘米

 习题 2/3

| 特征                    | 含义             |
| ----------------------- | ---------------- |
| Stnd                    | 车辆排放标准代码 |
| Cyl                     | 发动机气缸数     |
| Trans                   | 传动类型         |
| Sales Area（销售区域）  | 认证区域代码     |
| Cert Region（认证区域） | 认证区域代码     |

### 习题 

SmartWay 认证的根据是什么？

- [x] 温室气体得分
- [ ] 综合 MPG
- [x] 空气污染得分
- [ ] 燃料类型
- [ ] 位置

## 4_燃料经济性数据

该信息由美国环境保护局、流动源办公室、美国国家车辆与燃料排放实验室提供。

| 属性                 | 描述                                                         |
| -------------------- | ------------------------------------------------------------ |
| Model                | 车辆品牌和型号                                               |
| Displ                | 发动机排量 - 发动机的大小（升）                              |
| Cyl                  | 特定发动机中的气缸数                                         |
| Trans                | 传动类型和齿轮数                                             |
| Drive                | 驱动轴类型（2WD = 2 轮驱动，4WD = 4 轮/全轮驱动）            |
| Fuel                 | 燃油类型                                                     |
| Cert Region*         | 认证区域代码                                                 |
| Sales Area**         | 认证区域代码                                                 |
| Stnd                 | 车辆排放标准代码（[在此](https://www.epa.gov/greenvehicles/federal-and-california-light-duty-vehicle-emissions-standards-air-pollutants)查看车辆排放标准） |
| Stnd Description*    | 车辆排放标准说明                                             |
| Underhood ID         | 这是一个 12 位数的识别号码，可以在发动机舱排放标签上找到。EPA 要求使用此号码指定其"测定组"或"发动机系列"。 |
| Veh Class            | EPA 车辆类型                                                 |
| Air Pollution Score  | 空气污染评分（烟雾等级）                                     |
| City MPG             | 估计的城市 mpg（英里/加仑）                                  |
| Hwy MPG              | 估计的高速公路 mpg（英里/加仑）                              |
| Cmb MPG              | 估计的综合 mpg（英里/加仑）                                  |
| Greenhouse Gas Score | 温室气体等级                                                 |
| SmartWay             | 是、否或 Elite                                               |
| Comb CO2*            | 城市/高速公路综合二氧化碳尾气排放量（以克/英里为单位）       |

\* 不包括在 2008 数据集内 ** 不包括在 2018 数据集内



### 练习题

以下哪个是我们可以对此数据提出的相关问题？

- [ ] SmartWay 车辆是否更贵？
- [x] 是否有更多车型使用替代燃料来源？价格是多少？
- [x] 各车辆类型在燃料经济性方面的改进有多大？
- [x] SmartWay 车辆的特点是什么？
- [x] 哪些特征与更好的燃料经济性相关联？
- [x] 对于 2008 年生产且 2018 年仍在生产中的车型，mpg 有多少改进，哪些车辆的改进最多？

## 5_评估数据

在 Jupyter notebook 中使用 Pandas，探索 `all_alpha_08.csv` 和 `all_alpha_18.csv`，以回答 notebook 下面有关这些数据集特征的练习问题：

- 每个数据集中的样本数  
- 每个数据集中的列数
- 每个数据集中重复的行数
- 列的数据类型
- 具有缺失值的特征
- 每个数据集中特征的非空唯一值的数量 unique()
- 这些唯一值都是什么，以及每个的计数

## 6_清理列标签

### 1. 删除无关列

删除不一致（不同时存在于两个数据集中）的特征或与我们的问题无关的列。使用 [Pandas 的 drop](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) 函数。

##### 要删除的列：

- 2008 数据集中: `'Stnd'、'Underhood ID'、'FE Calc Appr'、'Unadj Cmb MPG'`
- 2018 数据集中: `'Stnd'、'Stnd Description'、'Underhood ID'、'Comb CO2'`

### 2. 重命名列

- 将 2008 数据集中的"Sales Area""列标签改为"Cert Region"以确保一致性。
- 重命名所有列标签以空格替换为下划线，并将所有内容转换为小写。（在 Python 中，下划线比空格更好用。例如，空格不允许你使用 `df.column_name` 代替 `df['column_name']` 来选择列，或使用 `query()`。保持小写和下划线一致也使列名更好记。）
- 将 2008 数据集中的"Sales Area""列标签改为"Cert Region"以确保一致性。

### 

### 清除列标签具体实现步骤如下：

使用 `all_alpha_08.csv` 和 `all_alpha_18.csv`

```python
# 加载数据集
import pandas as pd
df_08 = pd.read_csv('all_alpha_08.csv')
df_18 = pd.read_csv('all_alpha_18.csv')
```

```python
# 查看 2008 数据集
df_08.head(1)
```



```python
# 查看 2018 数据集
df_18.head(1)
```

#### 丢弃多余列

```python
# 从 2008 数据集中丢弃列
df_08.drop(['Stnd', 'Underhood ID', 'FE Calc Appr', 'Unadj Cmb MPG'], axis=1, inplace=True)

# 确认更改
df_08.head(1)
```



```python
# 从 2018 数据集中丢弃列
df_18.drop(['Stnd','Stnd Description','Underhood ID','Comb CO2'],axis=1,inplace=True)

# 确认更改
df_18.head()
```

#### 重命名列

```python
# 将销售区域重命名为特定区域
df_08.rename(columns={'Sales Area':'Cert Region'},inplace=True)

# 确认更改
df_08.head(1)
```



```python
# 在 2008 数据集中用下划线和小写标签代替空格
df_08.rename(columns=lambda x: x.strip().lower().replace(" ", "_"), inplace=True)

# 确认更改
df_08.head(1)
```



```python
# 在 2018 数据集中用下划线和小写标签代替空格
df_18.rename(columns=lambda x: x.strip().lower().replace(" ", "_"),inplace=True)

# 确认更改
df_18.head(1)
```



```python
# 确认 2008 和 2018 数据集的列标签相同
df_08.columns == df_18.columns
```



```
array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True], dtype=bool)
```



```python
# 确定所有的列标签都相同，如下所示
(df_08.columns == df_18.columns).all()
```



```
True
```



```python
# 保存新数据集，供下一段使用
df_08.to_csv('data_08.csv', index=True)
df_18.to_csv('data_18.csv', index=False)
```

```python
df_08.head()
```



## 7.过滤、丢弃空值、重复数据删除

使用 `data_08.csv` 和 `data_18.csv`

In [30]:

```
# 加载数据集
import pandas as pd
df_08 = pd.read_csv('data_08.csv')
df_18 = pd.read_csv('data_18.csv')
```

In [3]:

```
# 查看数据集维度
df_08.shape
```

Out[3]:

```
(986, 13)
```

In [5]:

```
# 查看数据集维度
df_18.shape
```

Out[5]:

```
(794, 13)
```

### 按认证区域过滤

In [4]:

```
# 过滤满足加州标准的行的数据集
df_08 = pd.read_csv('data_08.csv')
df_18 = pd.read_csv('data_18.csv')
```

In [5]:

```
# 确定唯一的认证区域是加州
df_08.head()
```

Out[5]:

|      | model     | displ | cyl     | trans   | drive | fuel     | veh_class   | air_pollution_score | city_mpg | hwy_mpg | cmb_mpg | greenhouse_gas_score | smartway |
| ---- | --------- | ----- | ------- | ------- | ----- | -------- | ----------- | ------------------- | -------- | ------- | ------- | -------------------- | -------- |
| 0    | ACURA MDX | 3.7   | (6 cyl) | Auto-S5 | 4WD   | Gasoline | SUV         | 7                   | 15       | 20      | 17      | 4                    | no       |
| 1    | ACURA RDX | 2.3   | (4 cyl) | Auto-S5 | 4WD   | Gasoline | SUV         | 7                   | 17       | 22      | 19      | 5                    | no       |
| 2    | ACURA RL  | 3.5   | (6 cyl) | Auto-S5 | 4WD   | Gasoline | midsize car | 7                   | 16       | 24      | 19      | 5                    | no       |
| 3    | ACURA TL  | 3.2   | (6 cyl) | Auto-S5 | 2WD   | Gasoline | midsize car | 7                   | 18       | 26      | 21      | 6                    | yes      |
| 4    | ACURA TL  | 3.5   | (6 cyl) | Auto-S5 | 2WD   | Gasoline | midsize car | 7                   | 17       | 26      | 20      | 6                    | yes      |

```
# 确定唯一的认证区域是加州
df_18.head()
```

Out[6]:

|      | model     | displ | cyl  | trans      | drive | fuel     | veh_class | air_pollution_score | city_mpg | hwy_mpg | cmb_mpg | greenhouse_gas_score | smartway |
| ---- | --------- | ----- | ---- | ---------- | ----- | -------- | --------- | ------------------- | -------- | ------- | ------- | -------------------- | -------- |
| 0    | ACURA RDX | 3.5   | 6.0  | SemiAuto-6 | 2WD   | Gasoline | small SUV | 3                   | 20       | 28      | 23      | 5                    | No       |
| 1    | ACURA RDX | 3.5   | 6.0  | SemiAuto-6 | 4WD   | Gasoline | small SUV | 3                   | 19       | 27      | 22      | 4                    | No       |
| 2    | ACURA TLX | 2.4   | 4.0  | AMS-8      | 2WD   | Gasoline | small car | 3                   | 23       | 33      | 27      | 6                    | No       |
| 3    | ACURA TLX | 3.5   | 6.0  | SemiAuto-9 | 2WD   | Gasoline | small car | 3                   | 20       | 32      | 24      | 5                    | No       |
| 4    | ACURA TLX | 3.5   | 6.0  | SemiAuto-9 | 4WD   | Gasoline | small car | 3                   | 21       | 30      | 24      | 5                    | No       |

In [9]:

```
# 将认证区域列从两个数据集中丢弃
df_08.drop(['cert_region''], axis=1, inplace=True))
df_18.drop(['cert_region''], axis=1, inplace=True))
```

```
  File "<ipython-input-9-79047c632cc4>", line 2
    df_08.drop(['cert_region''], axis=1, inplace=True))
                                                       ^
SyntaxError: EOL while scanning string literal
```

In [10]:

```
df_08.shape
```

Out[10]:

```
(986, 13)
```

In [11]:

```
df_18.shape
```

Out[11]:

```
(794, 13)
```

### 丢弃含有缺失值的行

In [17]:

```
# 查看 2008 年每个特征的缺失值数量
df_08.isnull().sum()
```

Out[17]:

```
model                   0
displ                   0
cyl                     0
trans                   0
drive                   0
fuel                    0
veh_class               0
air_pollution_score     0
city_mpg                0
hwy_mpg                 0
cmb_mpg                 0
greenhouse_gas_score    0
smartway                0
dtype: int64
```

In [18]:

```
# 查看 2018 年每个特征的缺失值数量
df_18.isnull().sum()
```

Out[18]:

```
model                   0
displ                   0
cyl                     0
trans                   0
drive                   0
fuel                    0
veh_class               0
air_pollution_score     0
city_mpg                0
hwy_mpg                 0
cmb_mpg                 0
greenhouse_gas_score    0
smartway                0
dtype: int64
```

In [ ]:

```
# 丢弃两个数据集中有任何空值的行
```

In [14]:

```
# 检查 2008 年的任何列是否有空值 - 应打印为“假”
df_08.isnull().sum().any()
```

Out[14]:

```
False
```

In [15]:

```
# 检查 2018 年的任何列是否有空值 - 应打印为“假”
df_18.isnull().sum().any()
```

Out[15]:

```
False
```

### 重复数据删除

In [22]:

```
# 打印 2008 年和 2018 年数据集的重复数量
df_08.duplicated().describe()
df_18.duplicated().describe()
```

Out[22]:

```
count       794
unique        1
top       False
freq        794
dtype: object
```

In [ ]:

```
# 丢弃两个数据集中的重复数据
```

In [25]:

```
# 再次打印重复数量，确认重复数据已删除——均应为 0 
df_08.duplicated().sum()
df_18.duplicated
```

Out[25]:

```
0
```

In [ ]:

```
# 保存进度，以便下一段使用
df_08.to_csv('data_08.csv', index=True)
df_18.to_csv('data_18.csv', index=False)
#记录我的修改，把False修改为True
```



## 8.检查数据类型

使用数 `data_08.csv` 和 `data_18.csv` 来检查数据类型

In [1]:

```
import pandas as pd
df_data_08 = pd.read_csv('data_08.csv')
df_data_18 = pd.read_csv('data_18.csv')
```

In [2]:

```
df_data_08.dtypes
```

Out[2]:

```
model                    object
displ                   float64
cyl                     float64
trans                    object
drive                    object
fuel                     object
cert_region              object
veh_class                object
air_pollution_score       int64
city_mpg                 object
hwy_mpg                  object
cmb_mpg                  object
greenhouse_gas_score      int64
smartway                 object
dtype: object
```

In [3]:

```
df_data_18.dtypes
```

Out[3]:

```
model                    object
displ                   float64
cyl                     float64
trans                    object
drive                    object
fuel                     object
cert_region              object
veh_class                object
air_pollution_score       int64
city_mpg                 object
hwy_mpg                  object
cmb_mpg                  object
greenhouse_gas_score      int64
smartway                 object
dtype: object
```

## 9.修正数据类型

在接下来的三个部分中，你将进行以下更改，以使数据类型一致和实用。

### 解决 `cyl` 数据类型

- 2008: 从字符串中提取整型。
- 2018: 将浮点型转换为整型。

### 解决 `air_pollution_score` 数据类型

- 2008: 将字符串转换为浮点型。
- 2018: 将整型转换为浮点型。

### 解决 `city_mpg`、`hwy_mpg`、`cmb_mpg` 数据类型

- 2008 和 2018: 将字符串转换为浮点型。

### 解决 `greenhouse_gas_score` 数据类型

- 2008: 从浮点型转换为整型。

在第一部分，你将解决第一个问题，修正 `cyl` 数据类型。



### 修正 `cyl` 数据类型

- 2008：从字符串中提取整数
- 2018：将浮点转换成整数

In [1]:

```
# 加载数据集
import pandas as pd
df_08 = pd.read_csv('data_08.csv')
df_18 = pd.read_csv('data_18.csv')
```

In [2]:

```
# 检查 2008 cyl 列的值数量
df_08['cyl'].value_counts()
```

Out[2]:

```
(6 cyl)     409
(4 cyl)     283
(8 cyl)     199
(5 cyl)      48
(12 cyl)     30
(10 cyl)     14
(2 cyl)       2
(16 cyl)      1
Name: cyl, dtype: int64
```

阅读 [这里](https://stackoverflow.com/questions/35376387/extract-int-from-string-in-pandas)，了解如何在下一步用 Pandas 从字符串中提取整数

In [4]:

```
# 从 2008 cyl 列的字符串中提取整数
df_08['cyl'] = df_08['cyl'].str.extract('(\d+)').astype(int)
```

```
/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)
  
```

In [5]:

```
# 再次检查 2008 cyl 列的值数量，确认更改
df_08['cyl'].value_counts()
```

Out[5]:

```
6     409
4     283
8     199
5      48
12     30
10     14
2       2
16      1
Name: cyl, dtype: int64
```

In [8]:

```
df_18['cyl'].value_counts()
```

Out[8]:

```
4.0     365
6.0     246
8.0     153
3.0      18
12.0      9
5.0       2
16.0      1
Name: cyl, dtype: int64
```

In [15]:

```
type(df_18['cyl'][0])
```

Out[15]:

```
numpy.float64
```

In [19]:

```
# 将 2018 cyl 列转换成整数
df_18['cyl'] = df_18['cyl'].astype(int)
```

- 参考上面的实现，在看一下官方文档的注释，然后就知道怎么转了，在下面检查转换是否成功

In [21]:

```
type(df_18['cyl'][0])
```

Out[21]:

```
numpy.int64
```

In [22]:

```
df_08.to_csv('data_08.csv', index=False)
df_18.to_csv('data_18.csv', index=False)
```

